{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d11-9IUd9mbE"
      },
      "source": [
        "## Processing Digits and Symbols "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1smSgnp4PRnQ"
      },
      "source": [
        "## Generate and save Dataset to Drive\n",
        "\n",
        "Only needed once for data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCMqlRxjCI3K",
        "outputId": "66ca6e64-2470-4b3f-8909-eea74c40eea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting idx2numpy\n",
            "  Downloading idx2numpy-1.2.3.tar.gz (6.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from idx2numpy) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from idx2numpy) (1.15.0)\n",
            "Building wheels for collected packages: idx2numpy\n",
            "  Building wheel for idx2numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idx2numpy: filename=idx2numpy-1.2.3-py3-none-any.whl size=7919 sha256=5f6cbb4dfc1c294aea62ccacb790ce40adbc137d0b1cad879da24b5d32fb4323\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/40/a8/6447ee4a00cb87e2084e1ef1df5c38433720cc1090be082842\n",
            "Successfully built idx2numpy\n",
            "Installing collected packages: idx2numpy\n",
            "Successfully installed idx2numpy-1.2.3\n"
          ]
        }
      ],
      "source": [
        "import idx2numpy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import image\n",
        "import os\n",
        "import struct\n",
        "import torch\n",
        "\n",
        "def load_train_images():\n",
        "    path = '/content/drive/MyDrive/dlproject/'\n",
        "\n",
        "    file = path + 'train-images.idx3-ubyte'\n",
        "    images = idx2numpy.convert_from_file(file)\n",
        "    # arr is now a np.ndarray type of object of shape 60000, 28, 28\n",
        "\n",
        "    with open(path + 'train-labels.idx1-ubyte','rb') as f:\n",
        "        magic, size = struct.unpack(\">II\", f.read(8))\n",
        "        data = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
        "        labels = data.reshape((size,)) # (Optional)\n",
        "\n",
        "    minuses = os.listdir(f'{path}dataset/minus-imgs/')\n",
        "    img_minuses = []\n",
        "    for p in minuses:\n",
        "      img = image.imread(f'{path}dataset/minus-imgs/{p}')\n",
        "      img_minuses.append(img)\n",
        "      print(f'\\r{p}', end='')\n",
        "\n",
        "    pluses = os.listdir(f'{path}dataset/plus-imgs/')\n",
        "    img_pluses = []\n",
        "    for p in pluses:\n",
        "      img = image.imread(f'{path}dataset/plus-imgs/{p}')\n",
        "      img_pluses.append(img)\n",
        "      print(f'\\r{p}', end='')\n",
        "\n",
        "    x = np.append(images, img_pluses + img_minuses, axis=0)\n",
        "    y = np.append(labels, [10]*len(pluses) + [11]*len(minuses), axis=0)\n",
        "\n",
        "    assert len(x) == len(y)\n",
        "    p = np.random.permutation(len(x))\n",
        "    return x[p], y[p]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9R9zVR-C4Dc",
        "outputId": "c9a4ad9c-1a12-404c-fd4c-d1dad365ed32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+_999.jpg"
          ]
        }
      ],
      "source": [
        "all_images, all_labels = load_train_images()\n",
        "\n",
        "path = '/content/drive/MyDrive/dlproject/cnn/'\n",
        "np.save(f\"{path}all_images.npy\", all_images)\n",
        "np.save(f\"{path}all_labels.npy\" , all_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLvfOIxlry7k"
      },
      "source": [
        "# Load Dataset from Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl2scQ5fsIAt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKaIG7uYq2S9"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/dlproject/cnn/'\n",
        "all_images = np.load(f\"{path}all_images.npy\")\n",
        "all_labels = np.load(f\"{path}all_labels.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "NoOaNNEgC_Z5",
        "outputId": "7403c3e7-c1b9-4a92-9aa8-4009a6acea23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "rand = np.random.randint(0, all_labels.shape[0] -1)\n",
        "plt.imshow(all_images[rand])\n",
        "print(all_labels[rand])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9wUGazvLVk5",
        "outputId": "d9edbef3-aebd-4437-ff31-805149feb120"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_images[0].dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK4mE38t_wBE"
      },
      "source": [
        "## Pytorch Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brhYIkMGx-ef"
      },
      "outputs": [],
      "source": [
        "#CUDA\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MXD3hBcPO3F"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, labels, images, transform=None, target_transform=None):\n",
        "        self.labels = labels\n",
        "        self.images = images\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.labels.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.labels[idx]\n",
        "        image = self.images[idx]\n",
        "        if self.transform:\n",
        "          image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "          label = self.target_transform(label)\n",
        "        return image.to(device), label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUjbXQQK-V-Q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "training_data = CustomImageDataset(all_labels[:-6000], all_images[:-6000], transform=ToTensor())\n",
        "test_data = CustomImageDataset(all_labels[-6000:], all_images[-6000:], transform=ToTensor())\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
        "\n",
        "#DO NOT TOUCH THIS, PLEASE :)\n",
        "class CNN(nn.Module):                  #Score: 99.2%\n",
        "    def __init__(self, out_classes):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Layer #1\n",
        "        self.conv1 = nn.Sequential(     #Input 28*28*1     \n",
        "            nn.Conv2d(\n",
        "                in_channels=1,              \n",
        "                out_channels=32,            \n",
        "                kernel_size=5,              \n",
        "                stride=1,                   \n",
        "                padding=0,                  \n",
        "            ),                          #Output 24*24*32                              \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(kernel_size=2) #Output 12*12*32\n",
        "        )\n",
        "        # Layer #2\n",
        "        self.conv2 = nn.Sequential(         \n",
        "            nn.Conv2d(\n",
        "                in_channels=32,              \n",
        "                out_channels=64,            \n",
        "                kernel_size=3,              \n",
        "                stride=1,                   \n",
        "                padding=0,\n",
        "            ),                          #Output 10*10*64\n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(kernel_size=2), #Output 5*5*64              \n",
        "        )\n",
        "        self.dense = nn.Sequential(\n",
        "            nn.Linear(5*5*64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64, out_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        # Put through 2 convolution layers and a 3L deep network with dropouts\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.size(0), -1)  #Flatten\n",
        "        output = self.dense(x)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5NK7u_g_bM1"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer, device=device):\n",
        "    model = model.to(device)\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model = model.to(device)\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph7LIi5E-YRj",
        "outputId": "c26e6414-90f9-4e26-d3e6-0673f52f7ffe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 26.127502  [    0/66000]\n",
            "loss: 0.606561  [ 6400/66000]\n",
            "loss: 0.253658  [12800/66000]\n",
            "loss: 0.157520  [19200/66000]\n",
            "loss: 0.070568  [25600/66000]\n",
            "loss: 0.119009  [32000/66000]\n",
            "loss: 0.174095  [38400/66000]\n",
            "loss: 0.053145  [44800/66000]\n",
            "loss: 0.082126  [51200/66000]\n",
            "loss: 0.053039  [57600/66000]\n",
            "loss: 0.081190  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 33.8%, Avg loss: 2.464166 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.023129  [    0/66000]\n",
            "loss: 0.009421  [ 6400/66000]\n",
            "loss: 0.122259  [12800/66000]\n",
            "loss: 0.164396  [19200/66000]\n",
            "loss: 0.046042  [25600/66000]\n",
            "loss: 0.074932  [32000/66000]\n",
            "loss: 0.118572  [38400/66000]\n",
            "loss: 0.093792  [44800/66000]\n",
            "loss: 0.033052  [51200/66000]\n",
            "loss: 0.019812  [57600/66000]\n",
            "loss: 0.368665  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 43.4%, Avg loss: 2.462988 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.014297  [    0/66000]\n",
            "loss: 0.028656  [ 6400/66000]\n",
            "loss: 0.109941  [12800/66000]\n",
            "loss: 0.020866  [19200/66000]\n",
            "loss: 0.047973  [25600/66000]\n",
            "loss: 0.070578  [32000/66000]\n",
            "loss: 0.056606  [38400/66000]\n",
            "loss: 0.013794  [44800/66000]\n",
            "loss: 0.020437  [51200/66000]\n",
            "loss: 0.105294  [57600/66000]\n",
            "loss: 0.102811  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 44.7%, Avg loss: 2.459784 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.023461  [    0/66000]\n",
            "loss: 0.012425  [ 6400/66000]\n",
            "loss: 0.019652  [12800/66000]\n",
            "loss: 0.019572  [19200/66000]\n",
            "loss: 0.016944  [25600/66000]\n",
            "loss: 0.005916  [32000/66000]\n",
            "loss: 0.021613  [38400/66000]\n",
            "loss: 0.014701  [44800/66000]\n",
            "loss: 0.098072  [51200/66000]\n",
            "loss: 0.099882  [57600/66000]\n",
            "loss: 0.054877  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 55.2%, Avg loss: 2.459509 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.041780  [    0/66000]\n",
            "loss: 0.030589  [ 6400/66000]\n",
            "loss: 0.019509  [12800/66000]\n",
            "loss: 0.142431  [19200/66000]\n",
            "loss: 0.055475  [25600/66000]\n",
            "loss: 0.058827  [32000/66000]\n",
            "loss: 0.006847  [38400/66000]\n",
            "loss: 0.019705  [44800/66000]\n",
            "loss: 0.020576  [51200/66000]\n",
            "loss: 0.002659  [57600/66000]\n",
            "loss: 0.011899  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 53.6%, Avg loss: 2.459172 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.023340  [    0/66000]\n",
            "loss: 0.012707  [ 6400/66000]\n",
            "loss: 0.008507  [12800/66000]\n",
            "loss: 0.073010  [19200/66000]\n",
            "loss: 0.012308  [25600/66000]\n",
            "loss: 0.033677  [32000/66000]\n",
            "loss: 0.004029  [38400/66000]\n",
            "loss: 0.096678  [44800/66000]\n",
            "loss: 0.040375  [51200/66000]\n",
            "loss: 0.033329  [57600/66000]\n",
            "loss: 0.025262  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 57.3%, Avg loss: 2.455707 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.301477  [    0/66000]\n",
            "loss: 0.057962  [ 6400/66000]\n",
            "loss: 0.041293  [12800/66000]\n",
            "loss: 0.008264  [19200/66000]\n",
            "loss: 0.006934  [25600/66000]\n",
            "loss: 0.003796  [32000/66000]\n",
            "loss: 0.013714  [38400/66000]\n",
            "loss: 0.019909  [44800/66000]\n",
            "loss: 0.008544  [51200/66000]\n",
            "loss: 0.054512  [57600/66000]\n",
            "loss: 0.146362  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 57.0%, Avg loss: 2.455014 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.008463  [    0/66000]\n",
            "loss: 0.011013  [ 6400/66000]\n",
            "loss: 0.000788  [12800/66000]\n",
            "loss: 0.015181  [19200/66000]\n",
            "loss: 0.016101  [25600/66000]\n",
            "loss: 0.021174  [32000/66000]\n",
            "loss: 0.010332  [38400/66000]\n",
            "loss: 0.001292  [44800/66000]\n",
            "loss: 0.034532  [51200/66000]\n",
            "loss: 0.007676  [57600/66000]\n",
            "loss: 0.004800  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 58.7%, Avg loss: 2.455273 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.083900  [    0/66000]\n",
            "loss: 0.004388  [ 6400/66000]\n",
            "loss: 0.039466  [12800/66000]\n",
            "loss: 0.231388  [19200/66000]\n",
            "loss: 0.002287  [25600/66000]\n",
            "loss: 0.063716  [32000/66000]\n",
            "loss: 0.001749  [38400/66000]\n",
            "loss: 0.020700  [44800/66000]\n",
            "loss: 0.015902  [51200/66000]\n",
            "loss: 0.004155  [57600/66000]\n",
            "loss: 0.006987  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 56.9%, Avg loss: 2.453347 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.017365  [    0/66000]\n",
            "loss: 0.014895  [ 6400/66000]\n",
            "loss: 0.014646  [12800/66000]\n",
            "loss: 0.007637  [19200/66000]\n",
            "loss: 0.066094  [25600/66000]\n",
            "loss: 0.007187  [32000/66000]\n",
            "loss: 0.050388  [38400/66000]\n",
            "loss: 0.000942  [44800/66000]\n",
            "loss: 0.005032  [51200/66000]\n",
            "loss: 0.005281  [57600/66000]\n",
            "loss: 0.026478  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 56.9%, Avg loss: 2.453131 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "model = CNN(12)\n",
        "\n",
        "learning_rate = 1e-3\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHwcf8OIIW9d",
        "outputId": "f49a29cf-4571-4a57-92dd-b72c23a1fd98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.482983  [    0/66000]\n",
            "loss: 0.496959  [ 6400/66000]\n",
            "loss: 0.109924  [12800/66000]\n",
            "loss: 0.168131  [19200/66000]\n",
            "loss: 0.052683  [25600/66000]\n",
            "loss: 0.083594  [32000/66000]\n",
            "loss: 0.064932  [38400/66000]\n",
            "loss: 0.102988  [44800/66000]\n",
            "loss: 0.111047  [51200/66000]\n",
            "loss: 0.104241  [57600/66000]\n",
            "loss: 0.043891  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 96.9%, Avg loss: 0.115548 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.073566  [    0/66000]\n",
            "loss: 0.122433  [ 6400/66000]\n",
            "loss: 0.031152  [12800/66000]\n",
            "loss: 0.112576  [19200/66000]\n",
            "loss: 0.112249  [25600/66000]\n",
            "loss: 0.310836  [32000/66000]\n",
            "loss: 0.010829  [38400/66000]\n",
            "loss: 0.048398  [44800/66000]\n",
            "loss: 0.007542  [51200/66000]\n",
            "loss: 0.246840  [57600/66000]\n",
            "loss: 0.049951  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 98.4%, Avg loss: 0.066432 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.165295  [    0/66000]\n",
            "loss: 0.044631  [ 6400/66000]\n",
            "loss: 0.046008  [12800/66000]\n",
            "loss: 0.000198  [19200/66000]\n",
            "loss: 0.045906  [25600/66000]\n",
            "loss: 0.148705  [32000/66000]\n",
            "loss: 0.425552  [38400/66000]\n",
            "loss: 0.052337  [44800/66000]\n",
            "loss: 0.075434  [51200/66000]\n",
            "loss: 0.095597  [57600/66000]\n",
            "loss: 0.031248  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 98.5%, Avg loss: 0.071207 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.090656  [    0/66000]\n",
            "loss: 0.119610  [ 6400/66000]\n",
            "loss: 0.005372  [12800/66000]\n",
            "loss: 0.058628  [19200/66000]\n",
            "loss: 0.015597  [25600/66000]\n",
            "loss: 0.006413  [32000/66000]\n",
            "loss: 0.007113  [38400/66000]\n",
            "loss: 0.124952  [44800/66000]\n",
            "loss: 0.001150  [51200/66000]\n",
            "loss: 0.058487  [57600/66000]\n",
            "loss: 0.071657  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 98.7%, Avg loss: 0.058433 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.080815  [    0/66000]\n",
            "loss: 0.080199  [ 6400/66000]\n",
            "loss: 0.001294  [12800/66000]\n",
            "loss: 0.005069  [19200/66000]\n",
            "loss: 0.010782  [25600/66000]\n",
            "loss: 0.177046  [32000/66000]\n",
            "loss: 0.013078  [38400/66000]\n",
            "loss: 0.067972  [44800/66000]\n",
            "loss: 0.144364  [51200/66000]\n",
            "loss: 0.146654  [57600/66000]\n",
            "loss: 0.007150  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 98.6%, Avg loss: 0.064823 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.000279  [    0/66000]\n",
            "loss: 0.176200  [ 6400/66000]\n",
            "loss: 0.001300  [12800/66000]\n",
            "loss: 0.240320  [19200/66000]\n",
            "loss: 0.086705  [25600/66000]\n",
            "loss: 0.015379  [32000/66000]\n",
            "loss: 0.099057  [38400/66000]\n",
            "loss: 0.094326  [44800/66000]\n",
            "loss: 0.007206  [51200/66000]\n",
            "loss: 0.000687  [57600/66000]\n",
            "loss: 0.042122  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 0.055442 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.017003  [    0/66000]\n",
            "loss: 0.005579  [ 6400/66000]\n",
            "loss: 0.027617  [12800/66000]\n",
            "loss: 0.093069  [19200/66000]\n",
            "loss: 0.000134  [25600/66000]\n",
            "loss: 0.076256  [32000/66000]\n",
            "loss: 0.000463  [38400/66000]\n",
            "loss: 0.001315  [44800/66000]\n",
            "loss: 0.045961  [51200/66000]\n",
            "loss: 0.021325  [57600/66000]\n",
            "loss: 0.028263  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 98.6%, Avg loss: 0.059449 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.007035  [    0/66000]\n",
            "loss: 0.023347  [ 6400/66000]\n",
            "loss: 0.006006  [12800/66000]\n",
            "loss: 0.004843  [19200/66000]\n",
            "loss: 0.277943  [25600/66000]\n",
            "loss: 0.008998  [32000/66000]\n",
            "loss: 0.031729  [38400/66000]\n",
            "loss: 0.001937  [44800/66000]\n",
            "loss: 0.068729  [51200/66000]\n",
            "loss: 0.002149  [57600/66000]\n",
            "loss: 0.053165  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 98.4%, Avg loss: 0.072529 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.016309  [    0/66000]\n",
            "loss: 0.059371  [ 6400/66000]\n",
            "loss: 0.058348  [12800/66000]\n",
            "loss: 0.005120  [19200/66000]\n",
            "loss: 0.003829  [25600/66000]\n",
            "loss: 0.058472  [32000/66000]\n",
            "loss: 0.074496  [38400/66000]\n",
            "loss: 0.047831  [44800/66000]\n",
            "loss: 0.041182  [51200/66000]\n",
            "loss: 0.003671  [57600/66000]\n",
            "loss: 0.000128  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 98.6%, Avg loss: 0.064699 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.023389  [    0/66000]\n",
            "loss: 0.000033  [ 6400/66000]\n",
            "loss: 0.002399  [12800/66000]\n",
            "loss: 0.006340  [19200/66000]\n",
            "loss: 0.102487  [25600/66000]\n",
            "loss: 0.018714  [32000/66000]\n",
            "loss: 0.019947  [38400/66000]\n",
            "loss: 0.000922  [44800/66000]\n",
            "loss: 0.018990  [51200/66000]\n",
            "loss: 0.000475  [57600/66000]\n",
            "loss: 0.250486  [64000/66000]\n",
            "Test Error: \n",
            " Accuracy: 99.2%, Avg loss: 0.041118 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "model = CNN(12)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adadelta(model.parameters())\n",
        "\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_sNLO9USS_q"
      },
      "outputs": [],
      "source": [
        "torch.save(model, '../resources/cnn.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.2 (v3.10.2:a58ebcc701, Jan 13 2022, 14:50:16) [Clang 13.0.0 (clang-1300.0.29.30)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
